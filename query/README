query.c
All code was written and tested on iOS 10.10.3
Edited with Sublime Text 2

Usage: ./query [ INDEXER_FILE ] [ CRAWLER_DIRECTORY ]

The INDEXER_FILE must be an existing file with each line in the format of the indexer output: [word] [number of documents it occurs in] [docID] [freq] [docId] [freq]…

The CRAWLER_DIRECTORY must be an existing directory that stores the files produced by crawler. The files must have integer names.

Command line inputs:
The user can write up to 1000 characters in the command line. Anything more than 1000 will not be processed. The input can be any combination of words and the operators “AND” and “OR”. The input should not start or end with an operator, and two operators should not be next to each other.


OUTPUTS:
The results from the users query will be printed to standard out. The urls and their document ids will be printed in order of rank. Rank is calculated by the total number of times the words that were searched for occurred in each document.


System Libraries:
stdio.h — needed to read in the indexer file

string.h — used to copy, compare, and create strings. Many functions from this library are utilized in order to format the input and output appropriately

stdlib.h — needed for the exit function, allocating memory, and converting strings to integers


Local includes from the tselibrary in the util directory:
../../util/web.h — provides string and word handling functionality

../../hashtable.h — provides hash table functionality including the definition of the structs HashTableNode and HashTable

../../file.h — provides directory, file handling functionality

../../indexer_utils.h — functions from indexer that are also utilized in query

Local include in the query/src directory:
operations.h — functions needed exclusively in query


COMPILING:
The program should be compiled using the make utility. The makefile is located in the top query directory. The makefile compiles indexer with a library in the util directory that includes much of the common functionality from crawler in the files hashtable.c/h, web.c/h, file.c/h, indexer_utils.h/c which are all in the util directory. Query should be compiled with the -Wall, -pedantic, and the -std=c11 flags.

The test target in the query makefile compiles the query_test.c file in the test subdirectory. This file unit tests the functions in operations.c.


TSE:
The query engine is one of three parts of the Tiny Search Engine. The other two parts —  Crawler and Indexer — are stored in directories at the same level as query. In order for the Tiny Search Engine to work properly, the programs should be executed in this order: crawler, indexer, query. The details for crawler and indexer are in their respective READMEs at the top of each of their directories. The shell script QEBATS.sh can also be used to run the Tiny Search Engine, but the user will not be able to choose their own queries, as the script is automated. The script compiles crawler, and crawls the page “http://old-www.cs.dartmouth.edu/~cs50/tse/“ at depth 3. In the interest of time, crawler will only sleep for .1 seconds between crawls. Crawler will include indirect links because the index.dat file provided by Zhao Tian corresponded to this type of crawl. It then compiles but does not run indexer because it has a bug for depths greater than 1. It proceeds to compile and run the query engine unit tests, and if they are all successful it will compile and run the query engine. The query engine will run based on a file provided by Zhao Tian from indexer at level 3. It will automatically process 4 searches. The results of QEBATS.sh will be directed to a log file called QEBATS.log. Each time the script is run, the QEBATS.log file will be overwritten. 